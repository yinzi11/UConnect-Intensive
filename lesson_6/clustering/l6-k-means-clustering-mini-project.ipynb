{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Intensive - Machine Learning Nanodegree\n",
    "# Lesson 6: K-Means Clustering Mini-Project\n",
    "\n",
    "\n",
    "## Objectives\n",
    "  - Perform [k-means clustering](http://scikit-learn.org/stable/modules/clustering.html#k-means) on the Enron Data Set.\n",
    "  - Visualize different clusters that form before and after feature scaling.\n",
    "  \n",
    "## Prerequisites\n",
    "  - You should have the following python packages installed:\n",
    "    - [matplotlib](http://matplotlib.org/index.html)\n",
    "    - [numpy](http://www.scipy.org/scipylib/download.html)\n",
    "    - [pandas](http://pandas.pydata.org/getpandas.html)\n",
    "    - [sklearn](http://scikit-learn.org/stable/install.html)\n",
    "\n",
    "## Acknowledgements\n",
    "  - The content of this notebook builds on the code from [k_means_cluster.py](https://github.com/udacity/ud120-projects/blob/master/k_means/k_means_cluster.py) from the [**ud120-projects**](https://github.com/udacity/ud120-projects) repo.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the [final_project_dataset.pkl](https://github.com/udacity/ud120-projects/blob/master/final_project/final_project_dataset.pkl) from the [**ud120-projects**](https://github.com/udacity/ud120-projects) repo. \n",
    "\n",
    "Inlcude this file in your lesson_6 folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering Mini-Project\n",
    "\n",
    "\n",
    "In this project, we’ll apply k-means clustering to our Enron financial data. Our final goal, of course, is to identify persons of interest; since we have labeled data, this is not a question that particularly calls for an unsupervised approach like k-means clustering.\n",
    "\n",
    "Nonetheless, you’ll get some hands-on practice with k-means in this project, and play around with feature scaling, which will give you a sneak preview of the next lesson’s material.\n",
    "The Enron dataset can be found here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Features\n",
    "\n",
    "The starter code can be found in k_means/k_means_cluster.py, which reads in the email + financial (E+F) dataset and gets us ready for clustering. You’ll start with performing k-means based on just two financial features--take a look at the code, and determine which features the code uses for clustering.\n",
    "\n",
    "Run the code, which will create a scatterplot of the data. Think a little bit about what clusters you would expect to arise if 2 clusters are created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "import pandas as pd \n",
    "from IPython.display import display, Image \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Draw(pred, features, poi, mark_poi=False, name=\"image.png\", f1_name=\"feature 1\", f2_name=\"feature 2\", cluster = None):\n",
    "    \"\"\" some plotting code designed to help you visualize your clusters \"\"\"\n",
    "\n",
    "    ### plot each cluster with a different color--add more colors for\n",
    "    ### drawing more than five clusters\n",
    "    \n",
    "    colors = [\"b\", \"c\", \"k\", \"m\", \"g\"]\n",
    "    for ii, pp in enumerate(pred):\n",
    "        plt.scatter(features[ii][0], features[ii][1], color = colors[pred[ii]])\n",
    "        \n",
    "    centers = cluster.cluster_centers_\n",
    "    if len(features_list) == 3:\n",
    "        for center in centers:\n",
    "            plt.scatter(center[0],center[1],marker='x',facecolor=\"r\",linewidth=3,s=100)\n",
    "            \n",
    "            \n",
    "    ### if you like, place red stars over points that are POIs (just for funsies)\n",
    "    if mark_poi:\n",
    "        for ii, pp in enumerate(pred):\n",
    "            if poi[ii]:\n",
    "                plt.scatter(features[ii][0], features[ii][1], color=\"r\", marker=\"*\")\n",
    "    plt.xlabel(f1_name)\n",
    "    plt.ylabel(f2_name)\n",
    "    plt.savefig(name)\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### load in the dict of dicts containing all the data on each person in the dataset\n",
    "data_dict = pickle.load( open(\"final_project_dataset.pkl\", \"r\") )\n",
    "\n",
    "### there's an outlier--remove it! \n",
    "data_dict.pop('TOTAL', 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which features does the code use for clustering? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### the input features we want to use \n",
    "### can be any key in the person-level dictionary (salary, director_fees, etc.) \n",
    "\n",
    "feature_1 = \"salary\"\n",
    "feature_2 = \"exercised_stock_options\"\n",
    "poi  = \"poi\"\n",
    "features_list = [poi, feature_1, feature_2]\n",
    "data = featureFormat(data_dict, features_list )\n",
    "poi, finance_features = targetFeatureSplit( data )\n",
    "\n",
    "\n",
    "for f1, f2 in finance_features:\n",
    "    plt.scatter( f1, f2, color = 'g' )\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying Clustering\n",
    "\n",
    "Deploy k-means clustering on the financial_features data, with 2 clusters specified as a parameter. Store your cluster predictions to a list called pred, so that the Draw() command at the bottom of the script works properly. In the scatterplot that pops up, are the clusters what you expected?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "\n",
    "### cluster here; create predictions of the cluster labels\n",
    "### for the data and store them to a list called pred\n",
    "\n",
    "\n",
    "\n",
    "### rename the \"name\" parameter when you change the number of features\n",
    "### so that the figure gets saved to a different file\n",
    "\n",
    "\n",
    "try:\n",
    "    Draw(pred, finance_features, poi, mark_poi=False, name=\"clusters2.pdf\", f1_name=feature_1, f2_name=feature_2, cluster = None)\n",
    "except NameError:\n",
    "    print \"no predictions object named pred found, no clusters to plot\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Clustering with 3 Features\n",
    "\n",
    "\n",
    "Add a third feature to features_list, “total_payments\". Now rerun clustering, using 3 input features instead of 2 (obviously we can still only visualize the original 2 dimensions). Compare the plot with the clusterings to the one you obtained with 2 input features. Do any points switch clusters? How many? This new clustering, using 3 features, couldn’t have been guessed by eye--it was the k-means algorithm that identified it.\n",
    "\n",
    "(You'll need to change the code that makes the scatterplot to accommodate 3 features instead of 2, see the comments in the starter code for instructions on how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_1 = \"salary\"\n",
    "feature_2 = \"exercised_stock_options\"\n",
    "\n",
    "\n",
    "poi  = \"poi\"\n",
    "features_list = [poi, feature_1, feature_2]\n",
    "data = featureFormat(data_dict, features_list )\n",
    "poi, finance_features = targetFeatureSplit( data )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    Draw(pred, finance_features, poi, mark_poi=False, name=\"clusters2.pdf\", f1_name=feature_1, f2_name=feature_2 ,cluster = None)\n",
    "except NameError:\n",
    "    print \"no predictions object named pred found, no clusters to plot\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Option Range\n",
    "\n",
    "\n",
    "In the next lesson, we’ll talk about feature scaling. It’s a type of feature preprocessing that you should perform before some classification and regression tasks. Here’s a sneak preview that should call your attention to the general outline of what feature scaling does.\n",
    "\n",
    "What are the maximum and minimum values taken by the “exercised_stock_options” feature used in this example?\n",
    "\n",
    "(NB: if you look at finance_features, there are some \"NaN\" values that have been cleaned away and replaced with zeroes--so while those might look like the minima, it's a bit deceptive because they're more like points for which we don't have information, and just have to put in a number. So for this question, go back to data_dict and look for the maximum and minimum numbers that show up there, ignoring all the \"NaN\" entries.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame object from the Enron data dictionary\n",
    "df = pd.DataFrame.from_dict(data_dict)\n",
    "\n",
    "# Take the transpose (.T) of the Enron DataFrame,\n",
    "# so that rows of the DataFrame correspond to individuals\n",
    "df = df.T\n",
    "\n",
    "print(\"DataFrame df has been created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"exercised_stock_options \\nmax:{} \\nmin:{}\".\\\n",
    "      format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salary Range\n",
    "\n",
    "What are the maximum and minimum values taken by “salary”?\n",
    "\n",
    "(NB: same caveat as in the last quiz. If you look at finance_features, there are some \"NaN\" values that have been cleaned away and replaced with zeroes--so while those might look like the minima, it's a bit deceptive because they're more like points for which we don't have information, and just have to put in a number. So for this question, go back to data_dict and look for the maximum and minimum numbers that show up there, ignoring all the \"NaN\" entries.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"salary \\nmax:{} \\nmin:{}\".\\\n",
    "      format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Changes\n",
    "\n",
    "\n",
    "The plot on the next slide shows the exact same clustering code that you just wrote, but in this example we applied feature scaling before performing the clustering.\n",
    "\n",
    "We want you to compare the clustering with scaling (on the next slide) with the first clustering visualization you produced, when you used two features in your clustering algorithm.\n",
    "\n",
    "Notice that now the range of the features has changed to [0.0, 1.0]. That's the only change we've made.\n",
    "\n",
    "In the next lesson you’ll learn a lot more about what feature scaling means, but for now, just look at the effect on the clusters--which point(s) switch their associated cluster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clusters before feature rescaling. \n",
    "\n",
    "Image('cluster_pic.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clusters after feature rescaling.\n",
    "\n",
    "Image(\"cluster_pic_feature_rescaling.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
